{
  "router": {
    "model": "qwen2.5-0.5b-instruct",
    "port": 3001,
    "context": 32768,
    "systemPromptPath": "prompts/router-classifier.md"
  },
  "lols-smart": {
    "default": {
      "model": "glm-4.7-flash",
      "systemPromptPath": "prompts/general-assistant.md"
    },
    "reason": {
      "model": "glm-4.7-flash",
      "systemPromptPath": "prompts/deep-thinker.md"
    },
    "chat": {
      "model": "glm-4.7-flash",
      "systemPromptPath": "prompts/chat-assistant.md"
    },
    "code": {
      "model": "glm-4.7-flash",
      "systemPromptPath": "prompts/coding-expert.md"
    },
    "vision": {
      "model": "minicpm-v-2.6",
      "systemPromptPath": "prompts/vision-expert.md"
    }
  },
  "models": {
    "qwen2.5-0.5b-instruct": {
      "type": "llama-cpp",
      "repo": "bartowski/Qwen2.5-0.5B-Instruct-GGUF",
      "file": "Qwen2.5-0.5B-Instruct-Q4_K_M.gguf",
      "context": 32768,
      "port": 8025
    },
    "qwen3-coder-30b-instruct": {
      "type": "llama-cpp",
      "repo": "bartowski/Qwen3-Coder-30B-A3B-Instruct-GGUF",
      "file": "Qwen3-Coder-30B-A3B-Instruct-Q4_K_M.gguf",
      "context": 32768,
      "port": 8029,
      "timeout": 300,
      "maxTokens": 8192,
      "performance": {
        "flashAttention": true,
        "batch": 4096,
        "ubatch": 512,
        "threads": 12,
        "parallel": 1,
        "contBatching": true,
        "cacheTypeK": "q4_0",
        "cacheTypeV": "q4_0",
        "gpuLayers": 20
      }
    },
    "qwen2.5-coder-14b-instruct": {
      "type": "llama-cpp",
      "repo": "bartowski/Qwen2.5-Coder-14B-Instruct-GGUF",
      "file": "Qwen2.5-Coder-14B-Instruct-Q4_K_M.gguf",
      "context": 81920,
      "port": 8026,
      "timeout": 300,
      "maxTokens": 8192,
      "performance": {
        "flashAttention": true,
        "batch": 4096,
        "ubatch": 1024,
        "threads": 12,
        "parallel": 1,
        "contBatching": true,
        "cacheTypeK": "q4_0",
        "cacheTypeV": "q4_0",
        "gpuLayers": 28
      }
    },
    "glm-4.7-flash": {
      "type": "llama-cpp",
      "repo": "unsloth/GLM-4.7-Flash-GGUF",
      "file": "GLM-4.7-Flash-Q4_K_M.gguf",
      "context": 131072,
      "port": 8027,
      "timeout": 300,
      "maxTokens": 8192,
      "temperature": 0.7,
      "topP": 1.0,
      "minP": 0.01,
      "repeatPenalty": 1.0,
      "performance": {
        "flashAttention": true,
        "batch": 4096,
        "ubatch": 1024,
        "threads": 12,
        "parallel": 1,
        "contBatching": true,
        "cacheTypeK": "q8_0",
        "cacheTypeV": "q8_0",
        "gpuLayers": -1
      }
    },
    "deepseek-coder-v2-lite": {
      "type": "llama-cpp",
      "repo": "bartowski/DeepSeek-Coder-V2-Lite-Instruct-GGUF",
      "file": "DeepSeek-Coder-V2-Lite-Instruct-Q4_K_M.gguf",
      "context": 65536,
      "port": 8033,
      "timeout": 300,
      "maxTokens": 8192,
      "temperature": 0.7,
      "topP": 0.95,
      "performance": {
        "flashAttention": true,
        "batch": 4096,
        "ubatch": 1024,
        "threads": 12,
        "parallel": 1,
        "contBatching": true,
        "cacheTypeK": "q8_0",
        "cacheTypeV": "q8_0",
        "gpuLayers": -1
      }
    },
    "minicpm-v-2.6": {
      "type": "llama-cpp",
      "repo": "openbmb/MiniCPM-V-2_6-gguf",
      "file": "ggml-model-Q4_K_M.gguf",
      "mmproj": "mmproj-model-f16.gguf",
      "context": 8192,
      "port": 8024,
      "supportsVision": true
    },
    "whisper-small": {
      "type": "whisper-cpp",
      "repo": "ggerganov/whisper.cpp",
      "file": "ggml-small.bin",
      "port": 8030,
      "language": "auto"
    },
    "whisper-base": {
      "type": "whisper-cpp",
      "repo": "ggerganov/whisper.cpp",
      "file": "ggml-base.bin",
      "port": 8031,
      "language": "auto"
    },
    "whisper-medium": {
      "type": "whisper-cpp",
      "repo": "ggerganov/whisper.cpp",
      "file": "ggml-medium.bin",
      "port": 8032,
      "language": "auto"
    }
  }
}
